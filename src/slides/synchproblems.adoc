---
title: "Synchronization Primitives and Problems"
date: 2016-02-08
description: >
  Continuation of an introduction to synchronization primitives and a
  discussion of several classic synchronization problems.
author: Geoffrey Challen
song:
  name: "Killer in the Streets"
  author: "Raveonettes"
	youtube: V93GmEBL3YY
---
[.nooutline.spelling_exception]
== Technical Women

image::women/034.jpg[width="100%", title="Irene Greif", link="https://en.wikipedia.org/wiki/Irene_Greif"]

[.h4.center]
icon:music[] http://www.theraveonettes.com/["Dead Sound" by the Raveonettes]

[.h4.center]
icon:music[] http://www.theraveonettes.com/[{song}]

video::BRnBQjaas3s[youtube,width=0,height=0]
video::{music}[youtube,width=0,height=0]

[.nooutline]
== Today

* Spinlocks, locks, and condition variables.
* Problems *with* synchronization primitives:
** Deadlock.
* Problems *using* synchronization primitives:
** Bounded buffer producer-consumer.
* Choosing the right primitive.

[.nooutline]
== $ cat announce.txt

[.slider]
* You need a partner. Now.
* A quick discussion of the new nit protocol.
[.slider]
** *If you find a bug in the website or any of our tools, or make a useful
contribution, you will receive some small amount of extra credit.* (Up to 5%
points.)
** However, you have to identify and fix the problem correctly. Don't email
us. Don't post in the forum. Fix the problem or add additional information
and then send us a pull request on GitHub.

== Locks

[.slider]
.*Locks* are a synchronization primitive used to implement critical sections.
* Threads *acquire* a lock when entering a critical section.
* Threads *release* a lock when leaving a critical section.

== Spinlocks

[.slider]
.What we discussed Friday is known as a *spinlock*:
* *lock* for the fact that it guards a critical section (we will have
more to say about locks next time), and
* *spin* describing the process of acquiring it.

[.slide]
--
Spinlocks are *rarely used* on their own to solve synchronization
problems.
--

[.slide]
--
Spinlocks are *commonly used* to build more useful synchronization
primitives.
--

== More Bank Example

[source,c,linenums,role='slide replace smaller']
----
void giveGWATheMoolah(account_t account, int largeAmount) {
  int gwaHas = get_balance(account);
  gwaHas = gwaHas + largeAmount;
  put_balance(account, gwaHas);
  notifyGWAThatHeIsRich(gwaHas);
  return;
}
----

[source,c,linenums,role='slide replace smaller end']
----
lock gwaWalletLock; // Need to initialize somewhere

void giveGWATheMoolah(account_t account, int largeAmount) {
+ lock_acquire(&gwaWalletLock);
  int gwaHas = get_balance(account);
  gwaHas = gwaHas + largeAmount;
  put_balance(account, gwaHas);
+ lock_release(&gwaWalletLock);
  notifyGWAThatHeIsRich(gwaHas);
  return;
}
----

[.slider]
.What happens if we call `lock_acquire()` while another thread is in the critical section?
* *The thread acquiring the lock must wait until the thread holding the
lock calls `lock_release()`*.

== How To Wait

[.slider]
.*How* do we wait?
* *Active* (or busy) waiting: repeat some action until the lock is
released.
* *Passive* waiting: tell the kernel what we are waiting for, go to
sleep, and rely on `lock_release` to awaken us.

== Spinning v. Sleeping

[.slider]
.There are cases where spinning is the right thing to do. *When?*
* Only on multicore systems. Why?
[.slider]
** On single core systems *nothing can change* unless we allow another thread
to run!
* If the critical section is *short*.
[.slider]
** Balance the length of the *critical section* against the overhead of a *context switch*.

== When to Spin

If the critical section is *short*:

[.slide]
--
image::figures/synch/sleeplocks.svg[width="70%"]
--

== When to Sleep

If the critical section is *long*:

[.slide]
--
image::figures/synch/spinlocks.svg[width="70%"]
--

== How to Sleep

[.slider]
.The kernel provide functionality allowing kernel threads to sleep and wake on a *key*:
* `thread_sleep(key)`: "Hey kernel, I'm going to sleep, but please wake
me up when *`key`* happens."
* `thread_wake(key)`: "Hey kernel, please wake up all (or one of) the
threads who were waiting for *`key`*."
* Similar functionality can be implemented in user space.

== Thread Communication

[.slider]
* Locks are designed to protect *critical sections*.
* `lock_release()` can be considered a *signal* from the thread inside the
critical section to other threads indicating that they can proceed.
** In order to receive this signal a thread *must be sleeping*.
* What about other kinds of signals that I might want to deliver?
** The buffer has data in it.
** Your child has exited.

== Condition Variables

[.slider]
* A *condition variable* is a signaling mechanism allowing threads to:
** `cv_wait` until a *condition* is true, and
** `cv_notify` other threads when the condition becomes true.
* The *condition* is usually represented as some change to shared state.
** The buffer has data in it: *`bufsize > 0`*.
** `cv_wait`: notify me when the buffer has data in it.
** `cv_signal`: I just put data in the buffer, so notify the threads that
are waiting for the buffer to have data.

== Condition Variables

[.slider]
* *Condition variable* can convey *more information* than locks about
some change to the state of the world.
* As an example, a buffer can be *full*, *empty*, or *neither*.
** If the buffer is *full*, we can let threads withdraw but not add
items.
** If the buffer is *empty*, we can let threads add but not withdraw
items.
** If the buffer is neither full nor empty, we can let threads add and
withdraw items.
* We have *three* different buffer states (full, empty, or neither) and
*two* different threads (producer, consumer).

== Condition Variables

[.slider]
.Why are condition variables a synchronization mechanism?
* Want to ensure that the condition *does not change* between checking it and
and deciding to wait!

[cols="2*",options='header',role='slide']
|===

| Thread A
| Thread B

a|
[source,python,role='smallest slide']
----
if (buffer_is_empty):
----
| {nbsp}

| {nbsp}
a|
[source,python,role='smallest slide']
----
put(buffer)
notify(buffer)
----

a|
[source,python,role='smallest slide']
----
sleep...
----
| {nbsp}

a|
[source,python,role='smallest slide']
----
...forever
----
| {nbsp}

|===

[.nooutline]
== Semaphores

* (See the forthcoming ASST1 walkthroughs and discuss in section this week.)

== Locking Multiple Resources

[.slider]
* *Locks* protect access to shared resources.
* Threads may need *multiple* shared resources to perform some
operation.

== Locking Multiple Resources

Consider two threads A and B that both need *simultaneous* access to
resources 1 and 2:

[.slider]
. *Thread A* runs, grabs the lock for *Resource 1*.
. → CONTEXT SWITCH ←
. *Thread B* runs, grabs the lock for *Resource 2*.
. → CONTEXT SWITCH ←
. *Thread A* runs, tries to acquire the lock for *Resource 2*.
. → THREAD A SLEEPS ←
. *Thread B* runs, tries to acquire the lock for *Resource 1*.
. → THREAD B SLEEPS ←

[.slider]
--
*Now what?*
--

== Deadlock

*Deadlock* occurs when a thread or set of threads are waiting for each
other to finish and thus nobody ever does.

== Self Deadlock

[.small]
--
[.slider]
.A *single thread* can deadlock. How?
* Thread A acquires Resource 1. Thread A tries to reacquire Resource 1.

[.slider]
.This seems inane. Why would this happen?
* `foo()` needs Resource 1. `bar()` needs Resource 1.
While locking Resource 1 `foo()` calls `bar()`.

[.slider]
.Can we solve this problem?
* *Yes!* Recursive locks. Allow a thread to reacquire a lock that it
already holds, as long as calls to acquire are matched by calls to
release.
* This kind of problem is not uncommon. You may want to implement
recursive locks for OS/161.
* (But don't make the locks we gave you suddenly recursive...)
--

== Conditions for Deadlock

[.slider]
.A deadlock *cannot occur* unless all of the following conditions are met:
* *Protected access* to shared resources, which implies waiting.
* *No resource preemption*, meaning that the system cannot forcibly
take a resource from a thread holding it.
* *Multiple independent requests*, meaning a thread can hold some
resources while requesting others.
* *Circular dependency graph*, meaning that Thread A is waiting for
Thread B which is waiting for Thread C which is waiting for Thread D
which is waiting for Thread A.

== Dining Philosophers

[.slider]
* "Classic" synchronization problem which I feel obligated to discuss.
* Illustrated below.

[.slide.replace]
--
image:figures/synch/philosophers.svg[width="50%", role='expand']
--

[.slide.replace]
--
image:figures/synch/philosophers-1.svg[width="50%", role='expand']
--

[.slide.replace]
--
image:figures/synch/philosophers-2.svg[width="50%", role='expand']
--

[.slide.replace]
--
image:figures/synch/philosophers-3.svg[width="50%", role='expand']
--

[.slide.replace]
--
image:figures/synch/philosophers-4.svg[width="50%", role='expand']
--

[.slide.replace]
--
image:figures/synch/philosophers-5.svg[width="50%", role='expand']
--

[.slide.replace]
--
image:figures/synch/philosophers-6.svg[width="50%", role='expand']
--

== Feeding Philosophers

[.slider]
.Breaking deadlock conditions usually requires eliminating one of the *requirements* for deadlock.
* *Don't wait*: don't sleep if you can't grab the second chopstick and
put down the first.
* *Break cycles*: usually by acquiring resources in a *well-defined
order*. Number chopsticks 0–4, always grab the higher-numbered chopstick
first.
* *Break out*: detect the deadlock cycle and forcibly take away a
resource from a thread to break it. (Requires a new mechanism.)
* *Don't make multiple independent requests*: grab *both* chopsticks at
once. (Requires a new mechanism.)

== Deadlock v. Starvation

[.slider]
.*Starvation* is an equally-problematic condition in which one or more threads do not make progress.
* Starvation differs from deadlock in that *some* threads make progress
and it is, in fact, those threads that are preventing the "starving"
threads from proceeding.

== Deadlock v. Race Conditions

What is better: a deadlock (perhaps from overly careful
synchronization) or a race condition (perhaps from a lack of correct
synchronization)?

[.slide]
--
I'll take the deadlock. *It's much easier to detect!*
--

== Producer-Consumer

.*Problem description*:
* Producer and consumer share a fixed-size buffer.
* Producer can add items to the buffer *if it is not full*.
* Consumer can withdraw items from the buffer *if it is not empty*.

[.slider]
.What do we want to ensure?
* Producer *must wait* if the buffer is full.
* Consumer *must wait* if the buffer is empty.
* Producers should not be sleeping if there is room in the buffer.
* Consumers should not be sleeping if there are items in the buffer.

== Producer-Consumer

[cols="2*"]
|===

a|
[source,c,linenum,role='smaller']
----
int count = 0;
void produce(item) {
  while (count == FULL) {
    // do something
  }
  put(buffer, item);
  count++;
}

item consume() {
  while (count == 0) {
    // do something
  }
  item = get(buffer, item);
  count--;
  return item;
}
----

a|
[.slider]
.What synchronization primitive is a good fit for this problem?
* *Condition variables*: I have a variable (`count`) and conditions that
require waiting (full, empty).

|===

== Producer-Consumer

[cols="2*"]
|===

a|
[source,c,linenum,role='smaller']
----
int count = 0;
struct * cv countCV;
struct * lock countLock;
void produce(item) {
  lock_acquire(countLock);
  while (count == FULL) {
    cv_wait(countCV, countLock);
  }
  put(buffer, item);
  count++;
  lock_release(countLock);
}

item consume() {
  lock_acquire(countLock);
  while (count == 0) {
    cv_wait(countCV, countLock);
  }
  item = get(buffer, item);
  count--;
  lock_release(countLock);
  return item;
}
----

a|
[.slider]
--
Looks good, right?
--

[.slider]
.Any time you call `cv_wait` *you must* call `cv_signal` or `cv_broadcast`!
* *But where?* Where does the condition change?

|===

== Producer-Consumer


[cols="2*"]
|===

a|
[source,c,linenum,role='smaller']
----
int count = 0;
struct * cv countCV;
struct * lock countLock;
void produce(item) {
  lock_acquire(countLock);
  while (count == FULL) {
    cv_wait(countCV, countLock);
  }
  put(buffer, item);
  count++;
  cv_broadcast(countCV, countLock);
  lock_release(countLock);
}

item consume() {
  lock_acquire(countLock);
  while (count == 0) {
    cv_wait(countCV, countLock);
  }
  item = get(buffer, item);
  count--;
  cv_broadcast(countCV, countLock);
  lock_release(countLock);
  return item;
}
----

a|
[.slider]
--
This works. But does it work well?
--

|===

== Producer-Consumer

[cols="2*"]
|===

a|
[source,c,linenum,role='smallest']
----
int count = 0;
struct * cv countCV;
struct * lock countLock;
void produce(item) {
  lock_acquire(countLock);
  while (count == FULL) {
    cv_wait(countCV, countLock);
  }
  put(buffer, item);
  count++;
  if (count == 1) {
    cv_broadcast(countCV, countLock);
  }
  lock_release(countLock);
}

item consume() {
  lock_acquire(countLock);
  while (count == 0) {
    cv_wait(countCV, countLock);
  }
  item = get(buffer, item);
  count--;
  if (count == FULL - 1) {
    cv_broadcast(countCV, countLock);
  }
  lock_release(countLock);
  return item;
}
----

a|

[.slider]
--
Approaching full victory. But why not use `cv_signal`?
--

|===

== Using the Right Tool

[.slider]
* Most problems can be solved with a *variety* of synchronization
primitives.
* However, there is usually *one primitive* that is more appropriate
than the others.
* You will have a chance to practice picking synchronization primitives
for ASST1, and throughout the class.

== Approaching Synchronization Problems

[.slider]
. Identify the constraints.
. Identify shared state.
. Choose a primitive.
. Pair waking and sleeping.
. Look out for multiple resource allocations: can lead to deadlock.
. Walk through simple examples and corner cases *before* beginning to code.

[.nooutline]
== Next Time

Return to the system calls: `exec`, `wait` and `exit`.
